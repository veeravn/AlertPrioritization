# Alert Prioritization System
## Overview
This Python script processes security alerts, calculates a risk score for each alert based on configurable risk factors, and classifies them as Low, Medium, or High priority. The system is designed to handle large datasets efficiently using parallel processing.

## Features

- **Scalable Architecture**:
  - Supports chunked processing to handle large datasets.
  - Parallel processing using `ProcessPoolExecutor` for improved performance.
- **Compute Risk Score**: Calculates a risk score for each alert based on severity, frequency of alerts from the same source IP, user role, and blacklist penalties.
- **Determine Priority**: Assigns a priority to each alert (`High`, `Medium`, or `Low`) based on the calculated risk score.
- **Error Handling and Logging**: Robust logging for debugging and monitoring during execution.

## Setup Instructions
### Requirements
- Python 3.8 or higher
- Required libraries:
    - pandas 2.2.0
    - argparse
    - multiprocessing
    - json
    - os
    - datetime
    - collections

### Installation
1. Clone or download the repository.
2. Install required dependencies:
```bash
pip install pandas==2.2.0
```
### Files in the Repository
- ```alert_prioritization.py```: Main script for processing alerts.
- ```config.json```: Configuration file for risk scoring.
- ```data.csv```: Sample input CSV file.
- ```alerts_with_priority.csv```: Example of output generated by the script.
- ```alert_prioritization_test.py```: Unit tests for the system.

## Configuration
The config.json file defines the weights and thresholds used for risk scoring. You can customize the following:

```json
{
  "alert_type_weights": {
    "Brute Force": 3,
    "DDoS": 4,
    "Malware": 2
  },
  "frequency_threshold": {
    "count": 5,
    "time_window": "10m"
  },
  "role_weights": {
    "Admin": 5,
    "Database": 4,
    "Web Server": 2
  },
  "ip_blacklist": [
    "192.168.1.100",
    "10.0.0.15"
  ],
  "severity_weight": 0.4,
  "frequency_weight": 0.3,
  "role_weight": 0.3
}
```
- **`frequency_threshold.time_window`**: Defines the time window for considering recent alerts (e.g., "10m" for 10 minutes).
- **`frequency_threshold.count`**: The minimum number of alerts required within the time window to contribute to the risk score.
- **`frequency_weight`**: The weight applied to the frequency factor in the risk score.
- **`severity_weight`**: The weight applied to the severity of the alert.
- **`role_weights`**: A dictionary that defines the weight for each user role (e.g., `admin`, `guest`).
- **`role_weight`**: The weight applied to the role's contribution to the risk score.
- **`ip_blacklist`**: A list of blacklisted IP addresses to penalize in the risk score.  This is assuming that the IP addresses in teh list are treated as individual IPs and not as a CIDR block of IPs.

## Usage
Run the script from the command line:

```bash
python alert_prioritization.py <data_file> <config_file>
```

### Example
```bash
python alert_prioritization.py data.csv config.json
```

### Input
- The input CSV file must include the following columns:
```alert_id```, ```alert_type```, ```severity```, ```source_ip```, ```target_ip```, ```timestamp```, ```alert_count```, ```user_role```.

### Output
The script generates an output CSV (```alerts_with_priority.csv```) with:

- ```alert_id```: Unique identifier of the alert.
- ```risk_score```: Computed risk score.
- ```priority```: Priority classification (Low, Medium, High).

It also prints a summary of priorities:

```
Priority Summary:
High      5
Medium    5
Low       0
dtype: int64
```
### Testing
Run unit tests to validate the functionality:

```bash 
python -m unittest test_alert_prioritization.py
```
1. **Parsing Timestamps**:
   - Valid timestamp parsing.
   - Invalid timestamp handling.

2. **Determining Priority**:
   - Correct classification of High, Medium, and Low priorities.

3. **Frequency Score Calculation**:
   - Proper calculation of frequency scores for alerts within a time window.
   - Handling of blacklisted IPs and edge cases (e.g., no alerts within the window).

4. **Risk Score Calculation**:
   - Comprehensive checks for severity, role weights, blacklist penalties, and frequency contributions.

5. **Chunk Processing**:
   - Ensures correct output for non-empty and empty datasets.
   - Handles malformed data gracefully with error logging.

## Notes
- The script is optimized for handling large datasets but may require tuning of chunk size and parallelism based on available hardware.
- Ensure input files follow the required format for correct processing.

Feel free to reach out for further support or enhancements!

